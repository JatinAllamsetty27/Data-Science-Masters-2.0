{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            border:#0b0265 solid;\n",
    "           background-color:#0077be;\n",
    "           font-size:110%;\n",
    "           letter-spacing:0.5px;\n",
    "            text-align: center\">\n",
    "\n",
    "<center><h1 style=\"padding: 25px 0px; background color:#0077be; font-weight: bold; font-family: Cursive\">\n",
    "Web Scrapping</h1></center>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is the process of extracting information from websites. It involves fetching the web page and then extracting necessary information. Web scraping is used because not all websites provide an API for accessing their data.\n",
    "\n",
    "Three areas where web scraping is used to get data:\n",
    "\n",
    "**E-commerce:** For price comparison and product data collection.\n",
    "\n",
    "**Job Portals:** For collecting job postings and details for analysis.\n",
    "\n",
    "**Real Estate:** For collecting property listing details and prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different methods used for web scraping include:\n",
    "\n",
    "Using libraries and frameworks: Like BeautifulSoup, Scrapy in Python.\n",
    "\n",
    "Web Scraping Tools: Like Octoparse, WebHarvy, etc.\n",
    "\n",
    "Using Web Browsers: Web browsers can be used along with extensions or developer tools.\n",
    "\n",
    "APIs: Some websites provide APIs which can be used to get data instead of scraping the website directly.\n",
    "\n",
    "Regular Expressions: Though not recommended, sometimes regular expressions are used to scrape data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library designed for web scraping purposes to pull the data out of HTML and XML files. It creates a parse tree that can be used to extract data easily. Beautiful Soup provides a few simple methods and properties to navigate and search the parse tree.\n",
    "\n",
    "Beautiful Soup is used because:\n",
    "\n",
    "It automatically converts incoming documents to Unicode and outgoing documents to UTF-8.\n",
    "\n",
    "It has a simple and consistent API which makes it easy to extract information.\n",
    "\n",
    "It sits on top of popular Python parsers like lxml and html5lib, allowing you to try out different parsing strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is used in the web scraping project to create a web application or server that displays the scraped data to users. Flask provides a lightweight way to integrate the Python backend with the web frontend. It's easy to get started with and flexible, making it ideal for small applications like the one in the web scraping project. With Flask, the scraped data can be presented in a structured manner in a web application, making it accessible and useful for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AWS EC2 (Elastic Compute Cloud):** This is a web service that provides resizable compute capacity in the cloud. It can be used to deploy the web application and run the web scraping scripts.\n",
    "\n",
    "**AWS RDS (Relational Database Service):** If the scraped data is stored in a database, RDS can be used to set up, operate, and scale a relational database in the cloud.\n",
    "\n",
    "**AWS S3 (Simple Storage Service):** If the scraped data or any other assets (like images, CSV files) need to be stored, S3 provides object storage with a web interface to store and retrieve any amount of data.\n",
    "These services together can provide a complete environment to run a web scraping project on the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
